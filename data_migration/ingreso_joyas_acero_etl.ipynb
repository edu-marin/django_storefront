{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# FUNCTIONS\n",
    "def get_sheet_names(file_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get the names of all sheets in an Excel file.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The path to the Excel file from which the sheet names are to be retrieved.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of strings, where each string is the name of a sheet in the Excel file.\n",
    "\n",
    "    Functionality:\n",
    "    - Reads an Excel file using pandas.\n",
    "    - Retrieves the names of all sheets in the Excel file.\n",
    "    \"\"\"\n",
    "    # Read the excel file using pandas\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    \n",
    "    # Get the names of all the sheets in the excel file\n",
    "    sheet_names = xls.sheet_names\n",
    "    \n",
    "    # Return the list of sheet names\n",
    "    return sheet_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names:\n",
      "['aretes', 'aretes_pistola', 'cadenas acero', 'dijes', 'pulseras', 'pulseras_varios', 'collares', 'collares_varios', 'anillos', 'juegos', 'Varios acero', 'proveedores']\n"
     ]
    }
   ],
   "source": [
    "# 1. Get sheet names from xlsx file\n",
    "file_path = \"data/ingreso_joyas_acero.xlsx\"\n",
    "sheet_names = get_sheet_names(file_path)\n",
    "print(\"Sheet names:\")\n",
    "print(sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Use pop method to exclude last sheet (proveedores) from the data consolidation process\n",
    "# Then read provedores sheet in adifferent df\n",
    "proveedores_name = sheet_names.pop()\n",
    "proveedores_df = pd.read_excel(file_path, sheet_name=proveedores_name)\n",
    "proveedores_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Name: aretes\n",
      "Shape: (374, 15)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_02/05/23',\n",
      "       'ingreso_19/07/23', 'ingreso_22/08/23', 'ingreso_22/02/24',\n",
      "       'ingreso_27/05/24', 'ingreso_21/06/24', 'costo', 'pvp', 'detalle',\n",
      "       'proveedor', 'nota', 'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: aretes_pistola\n",
      "Shape: (1, 11)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_09/05/23',\n",
      "       'ingreso_30/05/24', 'costo', 'pvp', 'detalle', 'proveedor', 'nota',\n",
      "       'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: cadenas acero\n",
      "Shape: (45, 11)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_17/07/23',\n",
      "       'ingreso_20/02/24', 'costo', 'pvp', 'detalle', 'proveedor', 'nota',\n",
      "       'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: dijes\n",
      "Shape: (57, 12)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_17/07/23',\n",
      "       'ingreso_20/02/24', 'ingreso_27/05/2024', 'costo', 'pvp', 'detalle',\n",
      "       'proveedor', 'nota', 'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: pulseras\n",
      "Shape: (80, 16)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_02/05/23',\n",
      "       'ingreso_17/07/23', 'ingreso_22/08/23', 'ingreso_20/02/24',\n",
      "       'ingreso_12/03/24', 'ingreso_31/05/24', 'ingreso_20/06/24', 'costo',\n",
      "       'pvp', 'detalle', 'proveedor', 'nota', 'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: pulseras_varios\n",
      "Shape: (61, 11)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_17/07/23',\n",
      "       'ingreso_31/01/24', 'costo', 'pvp', 'detalle', 'proveedor', 'nota',\n",
      "       'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: collares\n",
      "Shape: (61, 14)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_02/05/23',\n",
      "       'ingreso_15/07/23', 'ingreso_22/08/23', 'ingreso_20/02/24',\n",
      "       'ingreso 27/05/24', 'costo', 'pvp', 'detalle', 'proveedor', 'nota',\n",
      "       'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: collares_varios\n",
      "Shape: (1, 9)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_24/09/22', 'costo', 'pvp', 'detalle',\n",
      "       'proveedor', 'nota', 'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: anillos\n",
      "Shape: (50, 12)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_09/05/23',\n",
      "       'ingreso_15/07/23', 'ingreso_05/06/24', 'costo', 'pvp', 'detalle',\n",
      "       'proveedor', 'nota', 'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: juegos\n",
      "Shape: (118, 11)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_15/07/23',\n",
      "       'ingreso_05/06/24', 'costo', 'pvp', 'detalle', 'proveedor', 'nota',\n",
      "       'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: Varios acero\n",
      "Shape: (4, 9)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_25/06/24', 'costo', 'pvp', 'detalle',\n",
      "       'proveedor', 'nota', 'source'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Use a for loop to read spreadsheets in sheet_names and append them in a list\n",
    "# Replace the word \"inventario\" in column names with \"ingreso\" to simplify consolidation\n",
    "list_of_df = []\n",
    "for s in sheet_names:\n",
    "    print(f\"Sheet Name: {s}\")\n",
    "    # Read sheet and add new column with sheet name\n",
    "    df = pd.read_excel(file_path, sheet_name=s)\n",
    "    df[\"source\"] = s\n",
    "\n",
    "    # Replace \"invetario\" in column names with \"ingreso\"\n",
    "    df.columns = [c.replace(\"inventario\", \"ingreso\") for c in df.columns]\n",
    "    \n",
    "    # Append and print info\n",
    "    list_of_df.append(df)\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Column Names: {df.columns}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Name: all\n",
      "Shape: (852, 29)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 852 entries, 0 to 3\n",
      "Data columns (total 29 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   fecha_compra        852 non-null    object \n",
      " 1   codigo              852 non-null    object \n",
      " 2   ingreso_14/03/23    357 non-null    float64\n",
      " 3   ingreso_02/05/23    100 non-null    float64\n",
      " 4   ingreso_19/07/23    21 non-null     float64\n",
      " 5   ingreso_22/08/23    29 non-null     float64\n",
      " 6   ingreso_22/02/24    129 non-null    float64\n",
      " 7   ingreso_27/05/24    19 non-null     float64\n",
      " 8   ingreso_21/06/24    49 non-null     float64\n",
      " 9   costo               845 non-null    float64\n",
      " 10  pvp                 845 non-null    float64\n",
      " 11  detalle             852 non-null    object \n",
      " 12  proveedor           852 non-null    object \n",
      " 13  nota                49 non-null     object \n",
      " 14  source              852 non-null    object \n",
      " 15  ingreso_09/05/23    18 non-null     float64\n",
      " 16  ingreso_30/05/24    1 non-null      float64\n",
      " 17  ingreso_17/07/23    15 non-null     float64\n",
      " 18  ingreso_20/02/24    54 non-null     float64\n",
      " 19  ingreso_27/05/2024  9 non-null      float64\n",
      " 20  ingreso_12/03/24    5 non-null      float64\n",
      " 21  ingreso_31/05/24    16 non-null     float64\n",
      " 22  ingreso_20/06/24    2 non-null      float64\n",
      " 23  ingreso_31/01/24    35 non-null     float64\n",
      " 24  ingreso_15/07/23    14 non-null     float64\n",
      " 25  ingreso 27/05/24    30 non-null     float64\n",
      " 26  ingreso_24/09/22    1 non-null      float64\n",
      " 27  ingreso_05/06/24    27 non-null     float64\n",
      " 28  ingreso_25/06/24    4 non-null      float64\n",
      "dtypes: float64(23), object(6)\n",
      "memory usage: 199.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Consolidate (concat) spreadsheets in one dataframe\n",
    "all = pd.concat(list_of_df)\n",
    "print(f\"Sheet Name: all\")\n",
    "print(f\"Shape: {all.shape}\")\n",
    "all.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all[\"ingreso 27/05/24\"])\n",
    "all[\"ingreso 27/05/24\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with fecha_compra as string:\n",
      "Empty DataFrame\n",
      "Columns: [fecha_compra, codigo, source]\n",
      "Index: []\n",
      "\n",
      " New dtype of fecha_compra:\n",
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 852 entries, 0 to 3\n",
      "Series name: fecha_compra\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "852 non-null    datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 13.3 KB\n"
     ]
    }
   ],
   "source": [
    "# la columna fecha compra esta definida como objeto y deberia ser tipo date \n",
    "cont_string = all[\"fecha_compra\"].apply(lambda x: isinstance(x, str))\n",
    "print(\"Rows with fecha_compra as string:\")\n",
    "print(all[cont_string][[\"fecha_compra\",\"codigo\", \"source\"]])\n",
    "\n",
    "\n",
    "# Forzamos la transformación a tipo fecha con pd.to_datetime\n",
    "all[\"fecha_compra\"] = pd.to_datetime(all.fecha_compra, infer_datetime_format=True)\n",
    "\n",
    "# Chequeamos nuevamen\n",
    "print(\"\\nNew dtype of fecha_compra:\")\n",
    "all.fecha_compra.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transform (data quality)\n",
    "\n",
    "- 2.1 Verify data types of every column (manual)\n",
    "- 2.2 Check missing values for each column\n",
    "- 2.3 Check ```peso``` or ```costo_gramo``` equal to ```0```\n",
    "- 2.4 Rename provedores using ```proveedores_df```\n",
    "- 2.5 Melt: Dataframe from wide to long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fecha_compra            0\n",
      "codigo                  0\n",
      "ingreso_14/03/23      495\n",
      "ingreso_02/05/23      752\n",
      "ingreso_19/07/23      831\n",
      "ingreso_22/08/23      823\n",
      "ingreso_22/02/24      723\n",
      "ingreso_27/05/24      833\n",
      "ingreso_21/06/24      803\n",
      "costo                   7\n",
      "pvp                     7\n",
      "detalle                 0\n",
      "proveedor               0\n",
      "nota                  803\n",
      "source                  0\n",
      "ingreso_09/05/23      834\n",
      "ingreso_30/05/24      851\n",
      "ingreso_17/07/23      837\n",
      "ingreso_20/02/24      798\n",
      "ingreso_27/05/2024    843\n",
      "ingreso_12/03/24      847\n",
      "ingreso_31/05/24      836\n",
      "ingreso_20/06/24      850\n",
      "ingreso_31/01/24      817\n",
      "ingreso_15/07/23      838\n",
      "ingreso 27/05/24      822\n",
      "ingreso_24/09/22      851\n",
      "ingreso_05/06/24      825\n",
      "ingreso_25/06/24      848\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Check missing values per columns\n",
    "print(all.isnull().sum())\n",
    "\n",
    "# A. RESULTS\n",
    "# COLNAME: FINDINGS / ACTIONS:\n",
    "# fecha_compra: 4 missings/ Inspect and correct spreadsheet\n",
    "# talla: only anillos should have non missings / No action needed\n",
    "# ingreso_: missings are expected / No action needed\n",
    "# peso: 9 missings / Inspect and corrected in file\n",
    "# costo_gramo: 11 missings / Inspect and corrected in file\n",
    "\n",
    "# B. NOTES:\n",
    "# For juegos_piedras_perlas is ok to have missings in peso and costo gramo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missings in fecha_compra:\n",
      "Empty DataFrame\n",
      "Columns: [codigo, source]\n",
      "Index: []\n",
      "\n",
      "Missings in peso:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'peso'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# peso\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMissings in peso:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28;43mall\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeso\u001b[49m\u001b[38;5;241m.\u001b[39misnull(), [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodigo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# costo_gramo\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMissings in costo_gramo:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sfdc/lib/python3.8/site-packages/pandas/core/generic.py:5583\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5577\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5579\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5580\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5581\u001b[0m ):\n\u001b[1;32m   5582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'peso'"
     ]
    }
   ],
   "source": [
    "# INSPECT:\n",
    "# fecha_compra\n",
    "print('Missings in fecha_compra:')\n",
    "print(all.loc[all.fecha_compra.isnull(), ['codigo', 'source']])\n",
    "\n",
    "# peso\n",
    "print('\\nMissings in peso:')\n",
    "print(all.loc[all.peso.isnull(), ['codigo', 'source']])\n",
    "\n",
    "# costo_gramo\n",
    "print('\\nMissings in costo_gramo:')\n",
    "print(all.loc[all.costo_gramo.isnull(), ['codigo', 'source']])\n",
    "\n",
    "# costo\n",
    "print('\\nMissings in costo:')\n",
    "print(all.loc[all.costo.isnull(), ['codigo', 'source']])\n",
    "\n",
    "# costo\n",
    "print('\\nMissings proveedor:')\n",
    "print(all.loc[all.proveedor.isnull(), ['codigo', 'source']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Check peso or costo_gramo <= 0\n",
    "# ACTION NEEDED: Manually fix the file with non-zero values\n",
    "print('Rows with costo_gramo <= 0')\n",
    "print(all[all.costo_gramo<=0][['codigo', 'source', 'costo_gramo', 'peso', 'costo']])\n",
    "\n",
    "print('\\nRows with peso <= 0')\n",
    "print(all[all.peso<=0][['codigo', 'source', 'costo_gramo', 'peso', 'costo']])\n",
    "\n",
    "print('\\nRows with costo <= 0 as consequense of peso <= 0 OR costo_gramo <= 0')\n",
    "print(all[all.costo<=0][['codigo', 'source', 'costo_gramo', 'peso', 'costo']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Rename proveedores\n",
    "# Create dictionary where key is old name and values are new name\n",
    "dict_of_proveedores_1 = {k:v for k,v in zip(proveedores_df.Proveedor, proveedores_df['Nuevo Nombre'])}\n",
    "\n",
    "# Use the dictionary to replace old values\n",
    "all['proveedor'] = all.proveedor.replace(dict_of_proveedores_1)\n",
    "\n",
    "# Validate unuique values. Create a list of values that need manual changes\n",
    "print(f'Unique providers after 1st iteration: \\n{all.proveedor.unique()} \\n')\n",
    "\n",
    "# Create new dictionary for remaining values {old_name : new_name}\n",
    "dict_of_proveedores_2 = {\n",
    "    'China':'CHINA', \n",
    "    'Cirkon ':'CIRKON', \n",
    "    'Cirkon  ':'CIRKON',\n",
    "    'flavio jara':'FLAVIO JARA', \n",
    "    'CAMBIO DE CODIGO':'VOGA',\n",
    "        ' ':'VOGA',\n",
    "        '*': 'VOGA',\n",
    "        'LX, N.Y.':'LX USA',\n",
    "        'Alina ' :'ALINA PAZ',\n",
    "        'Andres ' :'ANDRES CADAVID',\n",
    "        'Feria Mia' : 'MIAMI',\n",
    "        'pedir': 'VOGA'\n",
    "    }\n",
    "\n",
    "# Use the new dictionary to replace remaining values\n",
    "all['proveedor'] = all.proveedor.replace(dict_of_proveedores_2)\n",
    "\n",
    "# Validate unique names again\n",
    "print(f'Unique providers after 2nd iteration: \\n{all.proveedor.unique()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Melt\n",
    "\n",
    "The pd.melt function in pandas is used to transform a DataFrame from a wide format to a long format. In the wide format, data is typically spread across multiple columns, while in the long format, data is stacked in a single column with an additional column indicating the original variable name (typically the column name in the wide format).\n",
    "\n",
    "Parameters of pd.melt:\n",
    "\n",
    "\t• id_vars: Specifies the columns to keep unchanged (identifier variables). These columns remain unpivoted.\n",
    "\t• value_vars (optional): Specifies the columns to unpivot. If not provided, all columns not specified in id_vars are used.\n",
    "\t• var_name: The name to use for the ‘variable’ column in the resulting DataFrame.\n",
    "\t• value_name: The name to use for the ‘value’ column in the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificar las columnas que no deben ser melted\n",
    "id_vars = ['fecha_compra', 'codigo', 'talla', 'peso',\n",
    "       'costo_gramo', 'costo', 'pvp', 'detalle', 'proveedor', 'nota', 'source']\n",
    "\n",
    "# Realizar el melt del dataframe\n",
    "all_melted = pd.melt(all, id_vars=id_vars, var_name='fecha_ingreso', value_name='count_items')\n",
    "\n",
    "# Limpiar la columna 'fecha' para extraer la fecha en el formato correcto\n",
    "all_melted['fecha_ingreso'] = all_melted['fecha_ingreso'].str.replace('ingreso_', '')\n",
    "\n",
    "# Eliminar las filas con valores perdidos en la columna 'items'\n",
    "# Esto corresponde a items que no tienen ingresos registrados\n",
    "all_melted.dropna(subset=['count_items'], inplace=True)\n",
    "\n",
    "all_melted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catch values with count_items == 0 and clean in file\n",
    "print(\"Count items with values = 0\")\n",
    "print(all_melted[all_melted.count_items==0][['codigo', 'source', 'fecha_ingreso', 'count_items']])\n",
    "\n",
    "print(\"\\n Lenght of fecha_ingreso\")\n",
    "print(all_melted.fecha_ingreso.str.len().value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count items to int64\n",
    "all_melted[\"count_items\"] = all_melted.count_items.astype(\"Int64\")\n",
    "\n",
    "# fecha_ingreso to datetime- Format \"dd/mm/yy\"\n",
    "all_melted[\"fecha_ingreso\"] = pd.to_datetime(all_melted.fecha_ingreso, format=\"%d/%m/%y\", errors='raise')  \n",
    "\n",
    "all_melted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_melted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save dataframe as Excel\n",
    "all_melted.to_excel(\"/workspaces/Voga/data_migration/data/all_plata_melted.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfdc",
   "language": "python",
   "name": "sfdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
