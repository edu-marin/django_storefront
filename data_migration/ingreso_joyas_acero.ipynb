{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# FUNCTIONS\n",
    "def get_sheet_names(file_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get the names of all sheets in an Excel file.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The path to the Excel file from which the sheet names are to be retrieved.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of strings, where each string is the name of a sheet in the Excel file.\n",
    "\n",
    "    Functionality:\n",
    "    - Reads an Excel file using pandas.\n",
    "    - Retrieves the names of all sheets in the Excel file.\n",
    "    \"\"\"\n",
    "    # Read the excel file using pandas\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    \n",
    "    # Get the names of all the sheets in the excel file\n",
    "    sheet_names = xls.sheet_names\n",
    "    \n",
    "    # Return the list of sheet names\n",
    "    return sheet_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names:\n",
      "['aretes', 'aretes_pistola', 'cadenas acero', 'dijes', 'pulseras', 'pulseras_varios', 'collares', 'collares_varios', 'anillos', 'juegos', 'Varios acero', 'proveedores']\n"
     ]
    }
   ],
   "source": [
    "# 1. Get sheet names from xlsx file\n",
    "file_path = \"data/ingreso_joyas_acero.xlsx\"\n",
    "sheet_names = get_sheet_names(file_path)\n",
    "print(\"Sheet names:\")\n",
    "print(sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use pop method to exclude last sheet (proveedores) from the data consolidation process\n",
    "# Then read provedores sheet in adifferent df\n",
    "proveedores_name = sheet_names.pop()\n",
    "proveedores_df = pd.read_excel(file_path, sheet_name=proveedores_name)\n",
    "proveedores_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Use a for loop to read spreadsheets in sheet_names and append them in a list\n",
    "# Replace the word \"inventario\" in column names with \"ingreso\" to simplify consolidation\n",
    "list_of_df = []\n",
    "for s in sheet_names:\n",
    "    print(f\"Sheet Name: {s}\")\n",
    "    # Read sheet and add new column with sheet name\n",
    "    df = pd.read_excel(file_path, sheet_name=s)\n",
    "    df[\"source\"] = s\n",
    "\n",
    "    # Replace \"invetario\" in column names with \"ingreso\"\n",
    "    df.columns = [c.replace(\"inventario\", \"ingreso\") for c in df.columns]\n",
    "    \n",
    "    # Append and print info\n",
    "    list_of_df.append(df)\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Column Names: {df.columns}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate (concat) spreadsheets in one dataframe\n",
    "all = pd.concat(list_of_df)\n",
    "print(f\"Sheet Name: all\")\n",
    "print(f\"Shape: {all.shape}\")\n",
    "all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transform (data quality)\n",
    "\n",
    "- 2.1 Verify data types of every column (manual)\n",
    "- 2.2 Check missing values for each column\n",
    "- 2.3 Check ```peso``` or ```costo_gramo``` equal to ```0```\n",
    "- 2.4 Rename provedores using ```proveedores_df```\n",
    "- 2.5 Melt: Dataframe from wide to long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Check missing values per columns\n",
    "print(all.isna().sum())\n",
    "\n",
    "# A. RESULTS\n",
    "# COLNAME: FINDINGS / ACTIONS:\n",
    "# fecha_compra: 4 missings/ Inspect and correct spreadsheet\n",
    "# talla: only anillos should have non missings / No action needed\n",
    "# ingreso_: missings are expected / No action needed\n",
    "# peso: 9 missings / Inspect and corrected in file\n",
    "# costo_gramo: 11 missings / Inspect and corrected in file\n",
    "\n",
    "# B. NOTES:\n",
    "# For juegos_piedras_perlas is ok to have missings in peso and costo gramo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT:\n",
    "# fecha_compra\n",
    "print('Missings in fecha_compra:')\n",
    "print(all.loc[all.fecha_compra.isnull(), ['codigo', 'source']])\n",
    "\n",
    "# peso\n",
    "print('\\nMissings in peso:')\n",
    "print(all.loc[all.peso.isnull(), ['codigo', 'source']])\n",
    "\n",
    "# peso\n",
    "print('\\nMissings in costo_gramo:')\n",
    "print(all.loc[all.costo_gramo.isnull(), ['codigo', 'source']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Check peso or costo_gramo <= 0\n",
    "# ACTION NEEDED: Manually fix the file with non-zero values\n",
    "print('Rows with costo_gramo <= 0')\n",
    "print(all[all.costo_gramo<=0][['codigo', 'source', 'costo_gramo', 'peso', 'costo']])\n",
    "\n",
    "print('\\nRows with peso <= 0')\n",
    "print(all[all.peso<=0][['codigo', 'source', 'costo_gramo', 'peso', 'costo']])\n",
    "\n",
    "print('\\nRows with costo <= 0 as consequense of peso <= 0 OR costo_gramo <= 0')\n",
    "print(all[all.costo<=0][['codigo', 'source', 'costo_gramo', 'peso', 'costo']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Rename proveedores\n",
    "# Create dictionary where key is old name and values are new name\n",
    "dict_of_proveedores_1 = {k:v for k,v in zip(proveedores_df.Proveedor, proveedores_df['Nuevo Nombre'])}\n",
    "\n",
    "# Use the dictionary to replace old values\n",
    "all['proveedor'] = all.proveedor.replace(dict_of_proveedores_1)\n",
    "\n",
    "# Validate unuique values. Create a list of values that need manual changes\n",
    "print(f'Unique providers after 1st iteration: \\n{all.proveedor.unique()} \\n')\n",
    "\n",
    "# Create new dictionary for remaining values {old_name : new_name}\n",
    "dict_of_proveedores_2 = {\n",
    "    'China':'CHINA', \n",
    "    'Cirkon ':'CIRKON', \n",
    "    'Cirkon  ':'CIRKON',\n",
    "    'flavio jara':'FLAVIO JARA', \n",
    "    'CAMBIO DE CODIGO':'VOGA',\n",
    "        ' ':'VOGA',\n",
    "        '*': 'VOGA',\n",
    "        'LX, N.Y.':'LX USA',\n",
    "        'Alina ' :'ALINA PAZ',\n",
    "        'Andres ' :'ANDRES CADAVID',\n",
    "        'Feria Mia' : 'MIAMI',\n",
    "        'pedir': 'VOGA'\n",
    "    }\n",
    "\n",
    "# Use the new dictionary to replace remaining values\n",
    "all['proveedor'] = all.proveedor.replace(dict_of_proveedores_2)\n",
    "\n",
    "# Validate unique names again\n",
    "print(f'Unique providers after 2nd iteration: \\n{all.proveedor.unique()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Melt\n",
    "\n",
    "The pd.melt function in pandas is used to transform a DataFrame from a wide format to a long format. In the wide format, data is typically spread across multiple columns, while in the long format, data is stacked in a single column with an additional column indicating the original variable name (typically the column name in the wide format).\n",
    "\n",
    "Parameters of pd.melt:\n",
    "\n",
    "\t•\tid_vars: Specifies the columns to keep unchanged (identifier variables). These columns remain unpivoted.\n",
    "\t•\tvalue_vars (optional): Specifies the columns to unpivot. If not provided, all columns not specified in id_vars are used.\n",
    "\t•\tvar_name: The name to use for the ‘variable’ column in the resulting DataFrame.\n",
    "\t•\tvalue_name: The name to use for the ‘value’ column in the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificar las columnas que no deben ser melted\n",
    "id_vars = ['fecha_compra', 'codigo', 'talla', 'peso',\n",
    "       'costo_gramo', 'costo', 'pvp', 'detalle', 'proveedor', 'nota', 'source']\n",
    "\n",
    "# Realizar el melt del dataframe\n",
    "all_melted = pd.melt(all, id_vars=id_vars, var_name='fecha_ingreso', value_name='count_items')\n",
    "\n",
    "# Limpiar la columna 'fecha' para extraer la fecha en el formato correcto\n",
    "all_melted['fecha_ingreso'] = all_melted['fecha_ingreso'].str.replace('ingreso_', '')\n",
    "\n",
    "\n",
    "# Eliminar las filas con valores perdidos en la columna 'items'\n",
    "# Esto corresponde a items que no tienen ingresos registrados\n",
    "all_melted.dropna(subset=['count_items'], inplace=True)\n",
    "\n",
    "all_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "all_melted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_melted.count_items.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catch values with count_items == 0 and clean in file\n",
    "print(all_melted[all_melted.count_items==0][['codigo', 'source', 'fecha_ingreso', 'count_items']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save dataframe as Excel\n",
    "all_melted.to_excel(\"/workspaces/Voga/data_migration/data/all_plata_melted.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
