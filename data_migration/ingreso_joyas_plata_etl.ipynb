{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# FUNCTIONS\n",
    "def get_sheet_names(file_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get the names of all sheets in an Excel file.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The path to the Excel file from which the sheet names are to be retrieved.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of strings, where each string is the name of a sheet in the Excel file.\n",
    "\n",
    "    Functionality:\n",
    "    - Reads an Excel file using pandas.\n",
    "    - Retrieves the names of all sheets in the Excel file.\n",
    "    \"\"\"\n",
    "    # Read the excel file using pandas\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    \n",
    "    # Get the names of all the sheets in the excel file\n",
    "    sheet_names = xls.sheet_names\n",
    "    \n",
    "    # Return the list of sheet names\n",
    "    return sheet_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names:\n",
      "['anillos_plata', 'dijes_plata', 'juegos_plata', 'collares_plata', 'aretes_plata', 'cadena_plata', 'pulseras_plata', 'varios_plata', 'juegos_piedras_perlas', 'proveedores']\n"
     ]
    }
   ],
   "source": [
    "# 1. Get sheet names from xlsx file\n",
    "file_path = \"data/ingreso_joyas_plata.xlsx\"\n",
    "sheet_names = get_sheet_names(file_path)\n",
    "print(\"Sheet names:\")\n",
    "print(sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Use pop method to exclude last sheet (proveedores) from the data consolidation process\n",
    "# Then read provedores sheet in adifferent df\n",
    "proveedores_name = sheet_names.pop()\n",
    "proveedores_df = pd.read_excel(file_path, sheet_name=proveedores_name)\n",
    "proveedores_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Name: anillos_plata\n",
      "Shape: (600, 15)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'talla', 'ingreso_14/03/23',\n",
      "       'ingreso_25/04/23', 'ingreso_27/03/24', 'ingreso_09/05/24', 'peso',\n",
      "       'costo_gramo', 'costo', 'pvp', 'detalle', 'proveedor', 'nota',\n",
      "       'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: dijes_plata\n",
      "Shape: (719, 19)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_28/04/23',\n",
      "       'ingreso_15/06/23', 'ingreso_18/08/23', 'ingreso_28/09/23',\n",
      "       'ingreso_19/12/23', 'ingreso_07/03/24', 'ingreso_10/05/24',\n",
      "       'ingreso_20/06/24', 'peso', 'costo_gramo', 'costo', 'pvp', 'detalle',\n",
      "       'proveedor', 'nota', 'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: juegos_plata\n",
      "Shape: (215, 18)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_28/04/23',\n",
      "       'ingreso_20/06/23', 'ingreso_28/09/23', 'ingreso_18/11/23',\n",
      "       'ingreso_15/12/23', 'ingreso_07/03/24', 'ingreso_16/05/24', 'peso',\n",
      "       'costo_gramo', 'costo', 'pvp', 'detalle', 'proveedor', 'nota',\n",
      "       'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: collares_plata\n",
      "Shape: (86, 16)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_26/04/23',\n",
      "       'ingreso_20/06/23', 'ingreso_18/11/23', 'ingreso_15/12/23',\n",
      "       'ingreso_10/05/24', 'peso', 'costo_gramo', 'costo', 'pvp', 'detalle',\n",
      "       'proveedor', 'nota', 'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: aretes_plata\n",
      "Shape: (558, 20)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_26/04/23',\n",
      "       'ingreso_20/06/23', 'ingreso_18/08/23', 'ingreso_28/09/23',\n",
      "       'ingreso_18/11/23', 'ingreso_15/12/23', 'ingreso_07/03/24',\n",
      "       'ingreso_16/05/24', 'ingreso_05/06/24', 'peso', 'costo_gramo', 'costo',\n",
      "       'pvp', 'detalle', 'proveedor', 'nota', 'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: cadena_plata\n",
      "Shape: (171, 16)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_21/04/23',\n",
      "       'ingreso_18/11/23', 'ingreso_19/12/23', 'ingreso_16/05/24',\n",
      "       'ingreso_14/06/24', 'peso', 'costo_gramo', 'costo', 'pvp', 'detalle',\n",
      "       'proveedor', 'nota', 'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: pulseras_plata\n",
      "Shape: (199, 20)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_14/03/23', 'ingreso_25/04/23',\n",
      "       'ingreso_20/06/23', 'ingreso_18/08/23', 'ingreso_28/09/23',\n",
      "       'ingreso_18/11/23', 'ingreso_15/12/23', 'ingreso_26/03/24',\n",
      "       'ingreso_16/05/24', 'ingreso_14/06/24', 'peso', 'costo_gramo', 'costo',\n",
      "       'pvp', 'detalle', 'proveedor', 'nota', 'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: varios_plata\n",
      "Shape: (10, 13)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_23/02/23', 'ingreso_28/09/23',\n",
      "       'ingreso_15/12/23', 'ingreso_08/03/24', 'peso', 'costo_gramo', 'costo',\n",
      "       'pvp', 'detalle', 'proveedor', 'source'],\n",
      "      dtype='object')\n",
      "\n",
      "Sheet Name: juegos_piedras_perlas\n",
      "Shape: (9, 9)\n",
      "Column Names: Index(['fecha_compra', 'codigo', 'ingreso_29/03/23', 'ingreso_04/06/24',\n",
      "       'costo', 'pvp', 'detalle', 'proveedor', 'source'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Use a for loop to read spreadsheets in sheet_names and append them in a list\n",
    "# Replace the word \"inventario\" in column names with \"ingreso\" to simplify consolidation\n",
    "list_of_df = []\n",
    "for s in sheet_names:\n",
    "    print(f\"Sheet Name: {s}\")\n",
    "    # Read sheet and add new column with sheet name\n",
    "    df = pd.read_excel(file_path, sheet_name=s)\n",
    "    df[\"source\"] = s\n",
    "\n",
    "    # Replace \"invetario\" in column names with \"ingreso\"\n",
    "    df.columns = [c.replace(\"inventario\", \"ingreso\") for c in df.columns]\n",
    "    \n",
    "    # Append and print info\n",
    "    list_of_df.append(df)\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Column Names: {df.columns}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Name: all\n",
      "Shape: (2567, 36)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2567 entries, 0 to 8\n",
      "Data columns (total 36 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   fecha_compra      2567 non-null   datetime64[ns]\n",
      " 1   codigo            2567 non-null   object        \n",
      " 2   talla             599 non-null    object        \n",
      " 3   ingreso_14/03/23  2041 non-null   float64       \n",
      " 4   ingreso_25/04/23  74 non-null     float64       \n",
      " 5   ingreso_27/03/24  1 non-null      float64       \n",
      " 6   ingreso_09/05/24  51 non-null     float64       \n",
      " 7   peso              2558 non-null   float64       \n",
      " 8   costo_gramo       2556 non-null   float64       \n",
      " 9   costo             2567 non-null   float64       \n",
      " 10  pvp               2567 non-null   float64       \n",
      " 11  detalle           2567 non-null   object        \n",
      " 12  proveedor         2567 non-null   object        \n",
      " 13  nota              445 non-null    object        \n",
      " 14  source            2567 non-null   object        \n",
      " 15  ingreso_28/04/23  95 non-null     float64       \n",
      " 16  ingreso_15/06/23  59 non-null     float64       \n",
      " 17  ingreso_18/08/23  73 non-null     float64       \n",
      " 18  ingreso_28/09/23  33 non-null     float64       \n",
      " 19  ingreso_19/12/23  61 non-null     float64       \n",
      " 20  ingreso_07/03/24  66 non-null     float64       \n",
      " 21  ingreso_10/05/24  74 non-null     float64       \n",
      " 22  ingreso_20/06/24  13 non-null     float64       \n",
      " 23  ingreso_20/06/23  33 non-null     float64       \n",
      " 24  ingreso_18/11/23  108 non-null    float64       \n",
      " 25  ingreso_15/12/23  136 non-null    float64       \n",
      " 26  ingreso_16/05/24  62 non-null     float64       \n",
      " 27  ingreso_26/04/23  60 non-null     float64       \n",
      " 28  ingreso_05/06/24  19 non-null     float64       \n",
      " 29  ingreso_21/04/23  23 non-null     float64       \n",
      " 30  ingreso_14/06/24  16 non-null     float64       \n",
      " 31  ingreso_26/03/24  3 non-null      float64       \n",
      " 32  ingreso_23/02/23  3 non-null      float64       \n",
      " 33  ingreso_08/03/24  4 non-null      float64       \n",
      " 34  ingreso_29/03/23  8 non-null      float64       \n",
      " 35  ingreso_04/06/24  1 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(29), object(6)\n",
      "memory usage: 742.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Consolidate (concat) spreadsheets in one dataframe\n",
    "all = pd.concat(list_of_df)\n",
    "print(f\"Sheet Name: all\")\n",
    "print(f\"Shape: {all.shape}\")\n",
    "all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transform (data quality)\n",
    "\n",
    "- 2.1 Verify data types of every column (manual)\n",
    "- 2.2 Check missing values for each column\n",
    "- 2.3 Check ```peso``` or ```costo_gramo``` equal to ```0```\n",
    "- 2.4 Rename provedores using ```proveedores_df```\n",
    "- 2.5 Melt: Dataframe from wide to long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fecha_compra           0\n",
      "codigo                 0\n",
      "talla               1968\n",
      "ingreso_14/03/23     526\n",
      "ingreso_25/04/23    2493\n",
      "ingreso_27/03/24    2566\n",
      "ingreso_09/05/24    2516\n",
      "peso                   9\n",
      "costo_gramo           11\n",
      "costo                  0\n",
      "pvp                    0\n",
      "detalle                0\n",
      "proveedor              0\n",
      "nota                2122\n",
      "source                 0\n",
      "ingreso_28/04/23    2472\n",
      "ingreso_15/06/23    2508\n",
      "ingreso_18/08/23    2494\n",
      "ingreso_28/09/23    2534\n",
      "ingreso_19/12/23    2506\n",
      "ingreso_07/03/24    2501\n",
      "ingreso_10/05/24    2493\n",
      "ingreso_20/06/24    2554\n",
      "ingreso_20/06/23    2534\n",
      "ingreso_18/11/23    2459\n",
      "ingreso_15/12/23    2431\n",
      "ingreso_16/05/24    2505\n",
      "ingreso_26/04/23    2507\n",
      "ingreso_05/06/24    2548\n",
      "ingreso_21/04/23    2544\n",
      "ingreso_14/06/24    2551\n",
      "ingreso_26/03/24    2564\n",
      "ingreso_23/02/23    2564\n",
      "ingreso_08/03/24    2563\n",
      "ingreso_29/03/23    2559\n",
      "ingreso_04/06/24    2566\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Check missing values per columns\n",
    "print(all.isna().sum())\n",
    "\n",
    "# A. RESULTS\n",
    "# COLNAME: FINDINGS / ACTIONS:\n",
    "# fecha_compra: 4 missings/ Inspect and correct spreadsheet\n",
    "# talla: only anillos should have non missings / No action needed\n",
    "# ingreso_: missings are expected / No action needed\n",
    "# peso: 9 missings / Inspect and corrected in file\n",
    "# costo_gramo: 11 missings / Inspect and corrected in file\n",
    "\n",
    "# B. NOTES:\n",
    "# For juegos_piedras_perlas is ok to have missings in peso and costo gramo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missings in fecha_compra:\n",
      "Empty DataFrame\n",
      "Columns: [codigo, source]\n",
      "Index: []\n",
      "\n",
      "Missings in peso:\n",
      "  codigo                 source\n",
      "0  JV001  juegos_piedras_perlas\n",
      "1  JV002  juegos_piedras_perlas\n",
      "2  JV003  juegos_piedras_perlas\n",
      "3  JV004  juegos_piedras_perlas\n",
      "4  JV005  juegos_piedras_perlas\n",
      "5  JV006  juegos_piedras_perlas\n",
      "6  JV007  juegos_piedras_perlas\n",
      "7  JV008  juegos_piedras_perlas\n",
      "8  JV009  juegos_piedras_perlas\n",
      "\n",
      "Missings in costo_gramo:\n",
      "     codigo                 source\n",
      "540  DP0435            dijes_plata\n",
      "291   AR288           aretes_plata\n",
      "0     JV001  juegos_piedras_perlas\n",
      "1     JV002  juegos_piedras_perlas\n",
      "2     JV003  juegos_piedras_perlas\n",
      "3     JV004  juegos_piedras_perlas\n",
      "4     JV005  juegos_piedras_perlas\n",
      "5     JV006  juegos_piedras_perlas\n",
      "6     JV007  juegos_piedras_perlas\n",
      "7     JV008  juegos_piedras_perlas\n",
      "8     JV009  juegos_piedras_perlas\n"
     ]
    }
   ],
   "source": [
    "# INSPECT:\n",
    "# fecha_compra\n",
    "print('Missings in fecha_compra:')\n",
    "print(all.loc[all.fecha_compra.isnull(), ['codigo', 'source']])\n",
    "\n",
    "# peso\n",
    "print('\\nMissings in peso:')\n",
    "print(all.loc[all.peso.isnull(), ['codigo', 'source']])\n",
    "\n",
    "# peso\n",
    "print('\\nMissings in costo_gramo:')\n",
    "print(all.loc[all.costo_gramo.isnull(), ['codigo', 'source']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with costo_gramo <= 0\n",
      "    codigo         source  costo_gramo  peso  costo\n",
      "447  AP189  anillos_plata          0.0   0.0    0.0\n",
      "\n",
      "Rows with peso <= 0\n",
      "     codigo          source  costo_gramo  peso  costo\n",
      "447   AP189   anillos_plata          0.0   0.0    0.0\n",
      "7     DP008     dijes_plata         95.0   0.0    0.0\n",
      "9     DP010     dijes_plata         32.2   0.0    0.0\n",
      "3    CLP004  collares_plata          7.0   0.0    0.0\n",
      "9    CLP010  collares_plata          7.0   0.0    0.0\n",
      "\n",
      "Rows with costo <= 0 as consequense of peso <= 0 OR costo_gramo <= 0\n",
      "     codigo          source  costo_gramo  peso  costo\n",
      "447   AP189   anillos_plata          0.0   0.0    0.0\n",
      "7     DP008     dijes_plata         95.0   0.0    0.0\n",
      "9     DP010     dijes_plata         32.2   0.0    0.0\n",
      "540  DP0435     dijes_plata          NaN  15.2    0.0\n",
      "3    CLP004  collares_plata          7.0   0.0    0.0\n",
      "9    CLP010  collares_plata          7.0   0.0    0.0\n",
      "291   AR288    aretes_plata          NaN   8.5    0.0\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Check peso or costo_gramo <= 0\n",
    "# ACTION NEEDED: Manually fix the file with non-zero values\n",
    "print('Rows with costo_gramo <= 0')\n",
    "print(all[all.costo_gramo<=0][['codigo', 'source', 'costo_gramo', 'peso', 'costo']])\n",
    "\n",
    "print('\\nRows with peso <= 0')\n",
    "print(all[all.peso<=0][['codigo', 'source', 'costo_gramo', 'peso', 'costo']])\n",
    "\n",
    "print('\\nRows with costo <= 0 as consequense of peso <= 0 OR costo_gramo <= 0')\n",
    "print(all[all.costo<=0][['codigo', 'source', 'costo_gramo', 'peso', 'costo']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique providers after 1st iteration: \n",
      "['VOGA' 'SOLEDAD SAENZ' 'CHINA' 'ALPHA TRADING' 'XAVIER GUILLEN'\n",
      " 'ALEX CASTRO' 'RIOBAMBA' 'ANDRES CADAVID' 'CIRKON' 'FLAVIO JARA'\n",
      " 'JUAN CHALCO' 'ALINA PAZ' 'PALACIO JOYAS' 'SEMPERTEGUI CHORDELEG'\n",
      " 'MILANUS USA' 'LX USA' 'ZAFIRO CHORDELEG' 'USA' 'P&K' 'BODY JEWELZ'\n",
      " 'MIAMI' 'FERNANDO JARA' 'PANAMA' 'GUILLERMO PARRA'] \n",
      "\n",
      "Unique providers after 2nd iteration: \n",
      "['VOGA' 'SOLEDAD SAENZ' 'CHINA' 'ALPHA TRADING' 'XAVIER GUILLEN'\n",
      " 'ALEX CASTRO' 'RIOBAMBA' 'ANDRES CADAVID' 'CIRKON' 'FLAVIO JARA'\n",
      " 'JUAN CHALCO' 'ALINA PAZ' 'PALACIO JOYAS' 'SEMPERTEGUI CHORDELEG'\n",
      " 'MILANUS USA' 'LX USA' 'ZAFIRO CHORDELEG' 'USA' 'P&K' 'BODY JEWELZ'\n",
      " 'MIAMI' 'FERNANDO JARA' 'PANAMA' 'GUILLERMO PARRA']\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Rename proveedores\n",
    "# Create dictionary where key is old name and values are new name\n",
    "dict_of_proveedores_1 = {k:v for k,v in zip(proveedores_df.Proveedor, proveedores_df['Nuevo Nombre'])}\n",
    "\n",
    "# Use the dictionary to replace old values\n",
    "all['proveedor'] = all.proveedor.replace(dict_of_proveedores_1)\n",
    "\n",
    "# Validate unuique values. Create a list of values that need manual changes\n",
    "print(f'Unique providers after 1st iteration: \\n{all.proveedor.unique()} \\n')\n",
    "\n",
    "# Create new dictionary for remaining values {old_name : new_name}\n",
    "dict_of_proveedores_2 = {\n",
    "    'China':'CHINA', \n",
    "    'Cirkon ':'CIRKON', \n",
    "    'Cirkon  ':'CIRKON',\n",
    "    'flavio jara':'FLAVIO JARA', \n",
    "    'CAMBIO DE CODIGO':'VOGA',\n",
    "        ' ':'VOGA',\n",
    "        '*': 'VOGA',\n",
    "        'LX, N.Y.':'LX USA',\n",
    "        'Alina ' :'ALINA PAZ',\n",
    "        'Andres ' :'ANDRES CADAVID',\n",
    "        'Feria Mia' : 'MIAMI',\n",
    "        'pedir': 'VOGA'\n",
    "    }\n",
    "\n",
    "# Use the new dictionary to replace remaining values\n",
    "all['proveedor'] = all.proveedor.replace(dict_of_proveedores_2)\n",
    "\n",
    "# Validate unique names again\n",
    "print(f'Unique providers after 2nd iteration: \\n{all.proveedor.unique()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Melt\n",
    "\n",
    "The pd.melt function in pandas is used to transform a DataFrame from a wide format to a long format. In the wide format, data is typically spread across multiple columns, while in the long format, data is stacked in a single column with an additional column indicating the original variable name (typically the column name in the wide format).\n",
    "\n",
    "Parameters of pd.melt:\n",
    "\n",
    "\t•\tid_vars: Specifies the columns to keep unchanged (identifier variables). These columns remain unpivoted.\n",
    "\t•\tvalue_vars (optional): Specifies the columns to unpivot. If not provided, all columns not specified in id_vars are used.\n",
    "\t•\tvar_name: The name to use for the ‘variable’ column in the resulting DataFrame.\n",
    "\t•\tvalue_name: The name to use for the ‘value’ column in the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3117 entries, 0 to 64174\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   fecha_compra   3117 non-null   datetime64[ns]\n",
      " 1   codigo         3117 non-null   object        \n",
      " 2   talla          646 non-null    object        \n",
      " 3   peso           3108 non-null   float64       \n",
      " 4   costo_gramo    3106 non-null   float64       \n",
      " 5   costo          3117 non-null   float64       \n",
      " 6   pvp            3117 non-null   float64       \n",
      " 7   detalle        3117 non-null   object        \n",
      " 8   proveedor      3117 non-null   object        \n",
      " 9   nota           670 non-null    object        \n",
      " 10  source         3117 non-null   object        \n",
      " 11  fecha_ingreso  3117 non-null   object        \n",
      " 12  count_items    3117 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(5), object(7)\n",
      "memory usage: 340.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Especificar las columnas que no deben ser melted\n",
    "id_vars = ['fecha_compra', 'codigo', 'talla', 'peso',\n",
    "       'costo_gramo', 'costo', 'pvp', 'detalle', 'proveedor', 'nota', 'source']\n",
    "\n",
    "# Realizar el melt del dataframe\n",
    "all_melted = pd.melt(all, id_vars=id_vars, var_name='fecha_ingreso', value_name='count_items')\n",
    "\n",
    "# Limpiar la columna 'fecha' para extraer la fecha en el formato correcto\n",
    "all_melted['fecha_ingreso'] = all_melted['fecha_ingreso'].str.replace('ingreso_', '')\n",
    "\n",
    "# Eliminar las filas con valores perdidos en la columna 'items'\n",
    "# Esto corresponde a items que no tienen ingresos registrados\n",
    "all_melted.dropna(subset=['count_items'], inplace=True)\n",
    "\n",
    "all_melted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       259\n",
       "1.0      1180\n",
       "2.0       688\n",
       "3.0       352\n",
       "4.0       175\n",
       "5.0       109\n",
       "6.0        98\n",
       "7.0        43\n",
       "8.0        33\n",
       "9.0        30\n",
       "10.0       34\n",
       "11.0       11\n",
       "12.0       19\n",
       "13.0       11\n",
       "14.0        7\n",
       "15.0        6\n",
       "16.0        8\n",
       "17.0        5\n",
       "18.0        3\n",
       "19.0        4\n",
       "20.0        4\n",
       "21.0        4\n",
       "22.0        7\n",
       "23.0        2\n",
       "24.0        3\n",
       "26.0        1\n",
       "27.0        2\n",
       "32.0        1\n",
       "33.0        1\n",
       "36.0        1\n",
       "37.0        1\n",
       "38.0        4\n",
       "40.0        1\n",
       "42.0        1\n",
       "48.0        2\n",
       "53.0        1\n",
       "60.0        1\n",
       "64.0        1\n",
       "83.0        1\n",
       "101.0       2\n",
       "104.0       1\n",
       "Name: count_items, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_melted.count_items.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       codigo         source fecha_ingreso  count_items\n",
      "6       AP003  anillos_plata      14/03/23          0.0\n",
      "15     AP0007  anillos_plata      14/03/23          0.0\n",
      "18     AP0009  anillos_plata      14/03/23          0.0\n",
      "19     AP0009  anillos_plata      14/03/23          0.0\n",
      "30     AP0015  anillos_plata      14/03/23          0.0\n",
      "...       ...            ...           ...          ...\n",
      "2299    CP122   cadena_plata      14/03/23          0.0\n",
      "2300    CP123   cadena_plata      14/03/23          0.0\n",
      "2301    CP124   cadena_plata      14/03/23          0.0\n",
      "20082   AR490   aretes_plata      28/09/23          0.0\n",
      "20083   AR491   aretes_plata      28/09/23          0.0\n",
      "\n",
      "[259 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Catch values with count_items == 0 and clean in file\n",
    "print(all_melted[all_melted.count_items==0][['codigo', 'source', 'fecha_ingreso', 'count_items']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save dataframe as Excel\n",
    "all_melted.to_excel(\"/workspaces/Voga/data_migration/data/all_plata_melted.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfdc",
   "language": "python",
   "name": "sfdc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
